{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84292d46-4845-45ec-916b-85eab863b14c",
   "metadata": {},
   "source": [
    "# SKA SDP Spectral Line Imaging Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab926f9-885e-486d-9086-e4a087af8894",
   "metadata": {},
   "source": [
    "+ [Overview of the pipeline](#Overview-of-the-pipeline)\n",
    "+ [Pipeline stages](#Pipeline-stages)\n",
    "+ [Simulate a small SKA-Mid data set](#Simulate-a-small-SKA-Mid-data-set)\n",
    "+ [Run the pipeline](#Run-the-pipeline)\n",
    "  - [Setting up the config file](#Setting-up-the-config-file)\n",
    "  - [Execute the pipeline](#Execute-the-pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be02868-9630-493f-956b-a59661942340",
   "metadata": {},
   "source": [
    "## Overview of the pipeline\n",
    "\n",
    "The SKA SDP spectral line imaging pipeline ([source code](https://gitlab.com/ska-telescope/sdp/science-pipeline-workflows/ska-sdp-spectral-line-imaging), [documentation](https://developer.skao.int/projects/ska-sdp-spectral-line-imaging/en/latest/)) produces channel maps, with an optional continuum subtraction step. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182b983-5f5a-4ec0-8d99-f8ec8422bfec",
   "metadata": {},
   "source": [
    "## Pipeline stages\n",
    "\n",
    "This section summarizes the different processing stages currently implemented in the pipeline. There is a one-to-one mapping between these pipeline stages and the parameter definition in the yaml file. Parameters relevant to each of the pipeline stage are described on [this page](https://developer.skao.int/projects/ska-sdp-spectral-line-imaging/en/latest/stage_config.html).\n",
    "\n",
    "+ load_data - allows users to do some basic data selection and filtering.\n",
    "+ vis_stokes_conversion - performs any necessary Stokes conversion\n",
    "+ read_model - If continuum subtraction needs to be done, this stage handles the continuum model that is specified as a FITS image.\n",
    "+ predict_stage - If continuum subtraction is requested, this stage converts the input FITS file into model visibilities.\n",
    "+ continuum_subtraction - This stage subtracts the model visibilities predicted in the previous step from the input visibility data.\n",
    "+ flagging - Performs an optional RFI flagging\n",
    "+ imaging - Produces the channel maps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721a3cd-1c7f-4e47-b7b2-0b25aa4cf5c2",
   "metadata": {},
   "source": [
    "## Simulate a small SKA-Mid data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91d732-878f-4dd2-9f6a-bb95c6d76a0f",
   "metadata": {},
   "source": [
    "Let's first simulate a small SKA-Mid dataset to test the spectral line imaging pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f50b1-6f4e-4cfc-9577-fa69f86c2815",
   "metadata": {},
   "source": [
    "Since we will use CASA to generate the mock dataset, first, setup the measures path correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6922dfd2-e00b-4e8a-8d56-777c198f0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pull_data: version is already at the expected version and force is False. Nothing was changed\n",
      "writing /root/.casarc...\n",
      "measures_update: version installed or checked less than 1 day ago, nothing updated or checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found existing .casarc...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from casaconfig import config, measures_update, pull_data, set_casacore_path\n",
    "\n",
    "measures_path = \"casa_data\"\n",
    "try:\n",
    "    os.mkdir(measures_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "pull_data(measures_path)\n",
    "config.measurespath = measures_path\n",
    "set_casacore_path(measures_path)\n",
    "measures_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46f99b-f858-46ed-8484-b54ad6e6be80",
   "metadata": {},
   "source": [
    "Next, simulate a dummy SKA-Mid AA* measurement set with 4 channels and 1 time resolution element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12812456-6401-4690-b451-5c70e42c379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from casatools import simulator, measures\n",
    "from casatasks import listobs\n",
    "from casatasks.private import simutil\n",
    "import shutil\n",
    "\n",
    "sm = simulator()\n",
    "su = simutil.simutil()\n",
    "me = measures()\n",
    "\n",
    "input_ms_name = \"spectral_imager_input.ms\"\n",
    "try:\n",
    "    shutil.rmtree(input_ms_name)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "sm.open(ms=input_ms_name)\n",
    "\n",
    "# Set the antenna configuration\n",
    "ant_config = \"../test_data/mid_aastar.txt\"\n",
    "(x, y, z, d, an, an2, telname, obspos) = su.readantenna(ant_config)\n",
    "sm.setconfig(\n",
    "    telescopename=telname,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    dishdiameter=d,\n",
    "    mount=[\"alt-az\"],\n",
    "    antname=an,\n",
    "    coordsystem=\"global\",\n",
    "    referencelocation=obspos,\n",
    ")\n",
    "\n",
    "# Setup the polarization mode\n",
    "sm.setfeed(mode=\"perfect X Y\", pol=[\"\"])\n",
    "\n",
    "# Spectral window setup\n",
    "sm.setspwindow(\n",
    "    spwname=\"Band 2\",\n",
    "    freq=\"1.4GHz\",\n",
    "    freqresolution=\"13.44kHz\",\n",
    "    deltafreq=\"13.44kHz\",\n",
    "    nchannels=4,\n",
    "    stokes=\"XX YY\",\n",
    ")\n",
    "\n",
    "# Specify the fields to observe\n",
    "sm.setfield(\n",
    "    sourcename=\"PKS1934-63\",\n",
    "    sourcedirection=me.direction(rf=\"J2000\", v0=\"19h39m25.0261s\", v1=\"-63d42m45.625s\"),\n",
    ")\n",
    "\n",
    "# Define integration time\n",
    "sm.settimes(\n",
    "    integrationtime=\"10s\",\n",
    "    usehourangle=True,\n",
    "    referencetime=me.epoch(\"UTC\", \"2019/10/4/00:00:00\"),\n",
    ")\n",
    "\n",
    "# Construct the measurement set and fill in the meta data\n",
    "sm.observe(sourcename=\"PKS1934-63\", spwname=\"Band 2\", starttime=\"-10s\", stoptime=\"+10s\")\n",
    "\n",
    "sm.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61232f-2bce-4b3d-b6bb-1775290f1a90",
   "metadata": {},
   "source": [
    "Next, create a skymodel containing two point sources with different spectral indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998fbe0b-693a-4ff6-999b-17a3aeb30322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from casatools import componentlist\n",
    "\n",
    "cl = componentlist()\n",
    "\n",
    "model_file = \"model.cl\"\n",
    "try:\n",
    "    shutil.rmtree(model_file)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# First component at the pointing center\n",
    "cl.addcomponent(\n",
    "    dir=\"J2000 19h39m25.0261s -63d42m45.625s\",\n",
    "    flux=1.0,\n",
    "    fluxunit=\"Jy\",\n",
    "    freq=\"1.4GHz\",\n",
    "    shape=\"point\",\n",
    "    spectrumtype=\"spectral index\",\n",
    "    index=0.1,\n",
    ")\n",
    "# Second component is an arcmin away\n",
    "cl.addcomponent(\n",
    "    dir=\"J2000 19h39m25.0261s -63d41m45.625s\",\n",
    "    flux=1.0,\n",
    "    fluxunit=\"Jy\",\n",
    "    freq=\"1.4GHz\",\n",
    "    shape=\"point\",\n",
    "    spectrumtype=\"spectral index\",\n",
    "    index=0.1,\n",
    ")\n",
    "cl.rename(filename=model_file)\n",
    "cl.done();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8b2d6-e117-4039-afb1-d94f7b8f1b58",
   "metadata": {},
   "source": [
    "Predict the model into the measurement set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95d590b-91dc-4471-9e13-47c4d0e05051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from casatasks import ft\n",
    "from casatools import table\n",
    "ft(vis=input_ms_name, complist=model_file, incremental=False, usescratch=True)\n",
    "# ft writes the visibilities to MODEL_DATA. Copy it to DATA and delete MODEL_DATA\n",
    "tb = table()\n",
    "tb.open(input_ms_name, nomodify=False)\n",
    "data=tb.getcol(\"MODEL_DATA\")\n",
    "tb.putcol(\"DATA\", data)\n",
    "tb.removecols(\"MODEL_DATA\")\n",
    "tb.removecols(\"CORRECTED_DATA\")\n",
    "tb.flush()\n",
    "tb.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df88174-1d1f-4cb0-86cd-c86916c7e45b",
   "metadata": {},
   "source": [
    "Convert the visibility data to MSv4 format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68a650-0a3a-4902-b258-8b78e811f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xradio.vis import convert_msv2_to_processing_set\n",
    "\n",
    "convert_msv2_to_processing_set(\n",
    "    in_file=\"spectral_imager_input.ms\", \n",
    "    out_file=\"spectral_imager_input.zarr\", \n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06062a78-6769-4db4-bddc-6ccd1419c271",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "We can access the pipeline either via the command line executable `spectral-line-imaging-pipeline` or using the API. In this section, we will look at how to run the pipeline from the command line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63968a30-ef4f-4808-885b-0defa20cea16",
   "metadata": {},
   "source": [
    "### Setting up the config file\n",
    "\n",
    "The input to `spectral-line-imaging-pipeline` is supplied using a config file. The easiest way to create the config file is to run \n",
    "\n",
    "`spectral-line-imaging-pipeline install-config --config-install-path ./` \n",
    "\n",
    "This creates a file named `spectral_line_imaging_pipeline.yml` in the directory mentioned above. The config file has three sections:\n",
    "+ **global parameters** section which is currently not in use\n",
    "+ **pipeline** section which is defines the pipeline stages to run\n",
    "+ **parameters** section is where the setup of each pipeline stage defined above is specified.\n",
    "\n",
    "As a first test run, I want to make a dirty Stokes I channel cube from the mock visibility dataset we simulated above. So, I've renamed the config file to `spectral_line_dirty.yml` and made the following changes:\n",
    "1. Disabled continuum subtraction and flagging by setting the following pipeline stages to `false`: `continuum_subtraction`, `predict_stage`, `flagging`, and `read_model`. I've also removed the corresponding sections from the **parameters** section. This is not strictly necessary but it makes the config file easy to read. \n",
    "2. Disable deconvolution by setting `parameters.n_iter_major: 0`. I've also removed the `deconvolution_params` block.\n",
    "3. Edit `vis_stokes_conversion.output_polarizations` and run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a0b09-021d-4504-96f5-9ec46604b5bb",
   "metadata": {},
   "source": [
    "### Execute the pipeline\n",
    "\n",
    "Next, run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad752b8a-0d5d-469c-a095-dc6843e55cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|2024-11-20T10:20:53.930Z|INFO|MainThread|run|pipeline.py#201||=============== START =====================\n",
      "1|2024-11-20T10:20:53.930Z|INFO|MainThread|run|pipeline.py#202||Executing spectral_line_imaging_pipeline pipeline with metadata:\n",
      "1|2024-11-20T10:20:53.931Z|INFO|MainThread|run|pipeline.py#203||Infile Path: spectral_imager_input.zarr\n",
      "1|2024-11-20T10:20:53.931Z|INFO|MainThread|run|pipeline.py#204||Stages: ['load_data', 'vis_stokes_conversion', 'imaging']\n",
      "1|2024-11-20T10:20:53.931Z|INFO|MainThread|run|pipeline.py#205||Configuration Path: spectral_line_dirty.yml\n",
      "1|2024-11-20T10:20:53.931Z|INFO|MainThread|run|pipeline.py#206||Current run output path : ./output/spectral_line_imaging_pipeline_2024-11-20T10:20:53\n",
      "1|2024-11-20T10:20:53.932Z|INFO|MainThread|run|pipeline.py#219||Selected stages to run: load_data, vis_stokes_conversion, imaging\n",
      "1|2024-11-20T10:20:54.067Z|INFO|MainThread|imaging_stage|imaging.py#196||Estimating cell size...\n",
      "1|2024-11-20T10:20:54.103Z|INFO|MainThread|imaging_stage|imaging.py#202||Using cell size = 0.08 arcseconds\n",
      "1|2024-11-20T10:20:54.103Z|INFO|MainThread|imaging_stage|imaging.py#211||Using image size = 256 pixels\n",
      "1|2024-11-20T10:20:54.132Z|INFO|MainThread|run|pipeline.py#226||Scheduling done, now executing the graph...\n",
      "1|2024-11-20T10:20:54.225Z|INFO|MainThread|run|pipeline.py#230||=============== FINISH =====================\n"
     ]
    }
   ],
   "source": [
    "!spectral-line-imaging-pipeline run --input spectral_imager_input.zarr --config spectral_line_dirty.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a235fb-86e0-4542-938c-71855cc9430e",
   "metadata": {},
   "source": [
    "If the pipeline runs successfully, you should see a new directory `output/spectral_line_imaging_pipeline_<time stamp>`, which contains the spectral cube along with pipeline log and a copy of the input config file. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
